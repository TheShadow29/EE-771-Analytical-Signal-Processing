\documentclass{article}
\usepackage[a4paper, tmargin=1in, bmargin=1in]{geometry}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage[justification=centering]{caption}

% \usepackage{parskip}
\usepackage{amsmath}
\usepackage{siunitx}
\sisetup{round-mode=places, round-precision=4}
\usepackage{ bbold }

\usepackage{pdflscape}
\usepackage{listings}
\usepackage{hyperref}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{float}

\title{EE 771 : Recent Topics in Analytical Signal Processing Assignment 2}
\author{Arka Sadhu - 140070011}
\date{\today}

\begin{document}
\maketitle

\section*{Q1}
Results are taken from the paper : M. Vetterli, P. Marziliano, and T. Blu, "Sampling Signals with Finite Rate of Innovation", IEEE Trans. on Signal Processing, Jun 2002.

We are given a 1 dimensional periodic signal $x(t)$ with period $T=1$ as:
$$x(t) = a_1 u(t - t_1) + a_2 u(t - t_2) - (a_1 + a_2) u(t - t_3)$$
with $0 < t_1 < t_2 < t_3$
\subsection*{1a}
We want to find the number of samples of $x(t) * sinc(Bt)$ which are sufficient for the reconstrucion of $x(t)$ and a suitable value for $B$. We note that $x(t)$ is an example of a non-uniform spline and therefore we can directly use Theorem 2 from the paper.

The minimum number of samples required are $N = 2M + 1$ where $M = \lfloor \frac{B \tau}{2} \rfloor$. We need $B \ge \rho$ where $\rho$ is the rate of innovation. In this case $\rho = \frac{2K}{\tau}$ and $K = 3$, $\tau = 1$. Therefore $\rho = 6$. But we note that $c_1 + c_2 + c_3 = 0$ which reduces one degree of freedom and hence $\tau = 5$. Thus, we need $B \ge 5Hz$. Choosing $B = 5Hz$ gives us $M = 2$ and $N = 5$, i.e. we can reconstruct the signal given 5 samples and choosing $B = 5Hz$.

\subsection*{1b}
We are now given a new 1d periodic signal $x_1(t)$ with the same period $T=1$ as:
$$x_1(t) = x(t) + b_1 \delta (t - t_1) - b_1 \delta (t - t_3)$$
Clearly, this is an example of the stream of derivatives of dirac deltas and we can use Theorem 3 from the paper. First we find the rate of innovation. The degrees of freedom increases by only from the previous part. This gives us $\rho = \frac{6}{1} = 6Hz$. Choosing $B = 6Hz$ we get $M = 3$ and correspondingly $N=7$.

\section*{Q2}
We want to prove that the Yule Walker system in the algorithm mentioned in the paper is invertible.

Denote the Yule Walker system matrix as $A$. We consider a $3x3$ matrix and note that the proof can be easily extended to any other $nxn$ matrix.

$A = \begin{bmatrix}
X[0] & X[-1] & X[-2]\\
X[1] & X[0] & X[-1]\\
X[2] & X[1] & X[0]
\end{bmatrix}$

Here $X[m] = \frac{1}{\tau} \sum_{k=0}^{K-1} c_k exp(-i 2 \pi m t_k / \tau)$. Denote $u_k = exp(-i 2\pi t_k / \tau)$. We can re-write $X[m] = \frac{1}{\tau} \sum_{k=0}^{K-1}c_k u_k^m$. In this case $K=3$. Also it is clear that the value of $\tau$ wouldn't make a difference in the invertibility of the matrix $A$. Thus we can write the following:
$$X[0] = c_1 + c_2 + c_3$$
$$X[1] = c_1u_1 + c_2 u_2 + c_3 u_3$$
$$X[2] = c_1 u_1^2 + c_2 u_2^2 + c_3u_3^2$$
$$X[-1] = c_1 u_1^{-1} + c_2 u_2^{-1} + c_3 u_3^{-1}$$
$$X[-2] = c_1 u_1^{-2} + c_2 u_2^{-2} + c_3 u_3^{-2}$$

We further note that we can write $A$ as $A = [A_1c | A_2c | A_3c]$. Here:
$$A_3 = \begin{bmatrix}
u_1^{-2} & u_2^{-2} & u_3^{-2}\\
u_1^{-1} & u_1^{-1} & u_3^{-1}\\
 1 &  1 & 1
\end{bmatrix}$$

$$A_2 = UA_3$$
$$A_1 = U^2 A_3$$

$$U = \begin{bmatrix}
u1 & 0 & 0\\
0 & u_2 & 0\\
0 & 0 & u_3
\end{bmatrix}$$

Moreover, $A_3$ is a permutation of a vander monde matrix. Therefore $A_3$ is invertible and therefore is non-singular. Now denote the determinant of $A$ by $det(A)$. We have
$$det(A) = det(A_3 [U^2c | Uc | c]) = det(A_3) det([U^2c | Uc | c])$$
The first term on the rhs is non-zero since $A_3$ is non-singular. The second term on the rhs is
$$det([U^2c | Uc | c]) = c_1 c_2 c_3 det(B)$$
$$B = \begin{bmatrix}
u1^2 & u1 & 1\\
u2^2 & u2 & 1\\
u3^2 & u3 & 1
\end{bmatrix}$$

Clearly B is also a vander monde matrix and therefore, $B$ is also non-singular. Also, $c_1, c_2, c_3$ are also non-zero (else there will be no diracs at those places and the dimension of the matrix will reduce). Therefore we have:
$$det(A) \ne 0$$
Consequently, we have proved that $A$ is invertible.

\section*{Q3}
Paper followed : M. Vetterli, P. Marziliano, and T. Blu, "Sampling Signals with Finite Rate of Innovation", IEEE Trans. on Signal Processing, Jun 2002.
We are given $u_1, u_2$ as the roots of unity. We want to construct the annihilation filter for the Fourier Series coefficients $$X[m] = \sum_{r=0}^3 c_r m^r u_1^m + \sum_{r=0}^1 d_r m^r u_2^m$$
This can be re-written as:
$$X[m] = u_1^m (c_0 + c_1 m + c_2 m^2 + c_3 m^3) + u_2^m (d_0 + d_1 m)$$
$$X[m] = u_1^m * poly(m, 3) + u_2^m * poly(m, 1)$$
Here $poly(m, r)$ denotes a polynomial in $m$ of degree $r$.
The annhilation filter $A(z)$ can be constructed in the following way (as noted in the paper):
\begin{itemize}
\item For $u_1^m poly(m, 3)$ we need the annihilation filter $A_1(z) = (1 - u_1z^{-4})$ (as stated in the paper). This is because, say $A_1(z) = \sum_{l=0}^4A_1[l]z^{-l}$, then $A_1^{(n)}(u_1) = 0 = \sum_{l=0}^4A_1[l] * l * (l-1) * .. * (l - n + 1) * z^{-l}$ and this would be true for all $n \le 3$. Thus $\sum_{l=0}^4A_1[l]P[l]u_1^{-l} = 0$. Here $P[l]$ is any polynomial of degree less than $3$. Moreover, this is smallest possible annihilation filter as we need to annihilate polynomials of degree 3.
\item Similarly, to annihilate $u_2^m poly(m, 1)$ we require $A_2(z) = (1 - u_2z^{-1})^2$. This is the smallest filter to annihilate the components of $u_2$.
\item To annihilate the sum we simply take the product of the two filters. $A(z) = A_1(z) A_2(z)$.
  $$A(z) = (1 - u_1z^{-1})^4 (1 - u_2z^{-1})^2$$
\end{itemize}

\section*{Q4}
Paper followed : A Generalized Sampling Method for Finite-Rate-of-Innovation-Signal Reconstruction by Chandra Sekhar Seelamantula, Member, IEEE, and Michael Unser, Fellow, IEEE.

We are given
$$x(t) = \sum_{k=1}^K b_k \delta (t - t_k)$$
Here all $t_k$ are in $(0, 1)$. Two RC filters with values $(R_1,C_1)$ and $(R_2, C_2)$ are used in parallel to filter out $x(t)$. We are also given the impulse response of the RC filters as:
$$h_i = exp(-R_i C_i) u(t)$$
where $i = 1, 2$ and $u(t)$ is the unit time step signal. We need to find the conditions on sampling interval $T$ so that the sampled signal $x(t) * h_i(t)|_{t = nT}$ are sufficient to reconstruct the parameters of $x(t)$.

Denote $\alpha_i=R_iC_i$ $$y_i(t) = x * h_i (t) = \sum_{k=1}^K b_k exp(-\alpha_i (t - t_k)) u(t - t_k)$$.

Let the sampling period be $T$. Then we get:
$$y_i (nT) = \sum_{k=1}^K b_k exp(-\alpha_i (nT - t_k)) u(nT - t_k), n \in \mathcal{Z}$$
Now we consider a discrete time finite impulse response filter specified by the Z-Transform:
$$G_i(z) = (1 - exp(-\alpha_i T)z^{-T})$$ It is noted that $G_i(z)$ is the convolutional inverse of the discrete time exponential $exp(-\alpha nT) u(nT)$.

Therefore, when the sequence $y_i[n] = y_i(nT)$ is processed by $G_i(z)$ it gives rise to a stream of kronecker impulses.
$$p_i(nT) = \sum_{k=1}^K b_k exp(-\alpha_i nT + \alpha_i t_k) (u(nT - t_k) - u((n-1)T -t_k))$$
$$p_i(nT) = \sum_{k=1}^K b_k exp(-\alpha_i r(t_k) T + \alpha_i t_k) \delta[n-r(t_k)]$$

Here $r(t_l) = \lceil t_k / T \rceil$ which indicates the ceiling operation.

If we assume that there is at most one dirac impulse in a sampling interval then the amplitude of the kronecker delta signal carries information about the position as well as the amplitude of the corresponding dirac impulse in a separable fashion. The condition boils down to
$$\min_{2 \le k \le K} \{t_k - t_{k-1}\} > T$$

Now we note that the $k^{th}$ non zero value in $p_i(nT)$ (i =1, 2) occur at the time instant $r(t_k)T$ just after $k^{th}$ dirac impulse has excited the respective analog system. We compute for i=1,2:
$$q_i[k] = p_i(r(t_k)T)exp(\alpha_i r(t_k) T) = b_k exp(\alpha_i t_k)$$

We solve the above (two equations for i=1,2) and get:
$$t_k = \frac{1}{\alpha_1 - \alpha_2} ln (\frac{q_1[k]}{q_2[k]}))$$
$$a_k = exp(-\frac{\alpha_1}{\alpha_1 - \alpha_2} ln(\frac{q_1[k]}{q_2[k]}))$$

\end{document}
